{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:32.866835800Z",
     "start_time": "2023-12-24T12:02:32.787216600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from timm.models.layers import DropPath\n",
    "from torchsummary import summary\n",
    "from lion_pytorch import Lion\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "502a0591ba123669",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:48.879216600Z",
     "start_time": "2023-12-24T12:02:32.804881100Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ab7d92e73929dc6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:51.036898Z",
     "start_time": "2023-12-24T12:02:48.883218700Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data.astype(np.float32)\n",
    "test_data.iloc[:, 1:] = test_data.iloc[:, 1:].astype(np.float32)\n",
    "train_data.iloc[:, 0] -= train_data.label.min()\n",
    "train_data.iloc[:, 1:] = train_data.iloc[:, 1:] / 255\n",
    "test_data.iloc[:, 1:] = test_data.iloc[:, 1:] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7078c78a908bc31",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:51.631162400Z",
     "start_time": "2023-12-24T12:02:51.038899900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min label: 0.0\n",
      "Max label: 35.0\n",
      "Min pixel: 0.0\n",
      "Max pixel: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Min label: {train_data.label.min()}')\n",
    "print(f'Max label: {train_data.label.max()}')\n",
    "print(f'Min pixel: {train_data.iloc[:, 1:].min().min()}')\n",
    "print(f'Max pixel: {train_data.iloc[:, 1:].max().max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b69ec85b68dfb851",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:51.679395500Z",
     "start_time": "2023-12-24T12:02:51.633149100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       label  pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  \\\n0        1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n1        1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n2        1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n3        1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n4        1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n...      ...      ...      ...      ...      ...      ...      ...      ...   \n80208    6.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n80209   19.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n80210   18.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n80211   27.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n80212   25.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n\n       pixel_7  pixel_8  ...  pixel_2490  pixel_2491  pixel_2492  pixel_2493  \\\n0          0.0      0.0  ...         0.0         0.0         0.0         0.0   \n1          0.0      0.0  ...         0.0         0.0         0.0         0.0   \n2          0.0      0.0  ...         0.0         0.0         0.0         0.0   \n3          0.0      0.0  ...         0.0         0.0         0.0         0.0   \n4          0.0      0.0  ...         0.0         0.0         0.0         0.0   \n...        ...      ...  ...         ...         ...         ...         ...   \n80208      0.0      0.0  ...         0.0         0.0         0.0         0.0   \n80209      0.0      0.0  ...         0.0         0.0         0.0         0.0   \n80210      0.0      0.0  ...         0.0         0.0         0.0         0.0   \n80211      0.0      0.0  ...         0.0         0.0         0.0         0.0   \n80212      0.0      0.0  ...         0.0         0.0         0.0         0.0   \n\n       pixel_2494  pixel_2495  pixel_2496  pixel_2497  pixel_2498  pixel_2499  \n0             0.0         0.0         0.0         0.0         0.0         0.0  \n1             0.0         0.0         0.0         0.0         0.0         0.0  \n2             0.0         0.0         0.0         0.0         0.0         0.0  \n3             0.0         0.0         0.0         0.0         0.0         0.0  \n4             0.0         0.0         0.0         0.0         0.0         0.0  \n...           ...         ...         ...         ...         ...         ...  \n80208         0.0         0.0         0.0         0.0         0.0         0.0  \n80209         0.0         0.0         0.0         0.0         0.0         0.0  \n80210         0.0         0.0         0.0         0.0         0.0         0.0  \n80211         0.0         0.0         0.0         0.0         0.0         0.0  \n80212         0.0         0.0         0.0         0.0         0.0         0.0  \n\n[80213 rows x 2501 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel_0</th>\n      <th>pixel_1</th>\n      <th>pixel_2</th>\n      <th>pixel_3</th>\n      <th>pixel_4</th>\n      <th>pixel_5</th>\n      <th>pixel_6</th>\n      <th>pixel_7</th>\n      <th>pixel_8</th>\n      <th>...</th>\n      <th>pixel_2490</th>\n      <th>pixel_2491</th>\n      <th>pixel_2492</th>\n      <th>pixel_2493</th>\n      <th>pixel_2494</th>\n      <th>pixel_2495</th>\n      <th>pixel_2496</th>\n      <th>pixel_2497</th>\n      <th>pixel_2498</th>\n      <th>pixel_2499</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>80208</th>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>80209</th>\n      <td>19.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>80210</th>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>80211</th>\n      <td>27.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>80212</th>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>80213 rows × 2501 columns</p>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b46579e49b618af9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:51.700592100Z",
     "start_time": "2023-12-24T12:02:51.681398100Z"
    }
   },
   "outputs": [],
   "source": [
    "img_tform_1 = transforms.Compose([\n",
    "    transforms.ToPILImage(), transforms.ToTensor(), transforms.Normalize(mean=(0.0253), std=(0.1131))])\n",
    "\n",
    "img_tform_2 = transforms.Compose([\n",
    "    transforms.ToPILImage(), transforms.RandomRotation(15), transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.0253), std=(0.1131))])\n",
    "\n",
    "img_tform_3 = transforms.Compose([\n",
    "    transforms.ToPILImage(), transforms.RandomRotation(45), transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.0253), std=(0.1131))])\n",
    "\n",
    "img_tform_4 = transforms.Compose([\n",
    "    transforms.ToPILImage(), transforms.RandomAffine(degrees=20, translate=(0.15, 0.15), scale=(0.85, 0.85)), \\\n",
    "    transforms.ToTensor(), transforms.Normalize(mean=(0.0253), std=(0.1131))])\n",
    "\n",
    "img_tform_5 = transforms.Compose([\n",
    "    transforms.ToPILImage(), transforms.RandomAffine(degrees=15, translate=(0.25, 0.25)), \\\n",
    "    transforms.ToTensor(), transforms.Normalize(mean=(0.0253), std=(0.1131))])\n",
    "\n",
    "img_tform_6 = transforms.Compose([\n",
    "    transforms.ToPILImage(), transforms.RandomAffine(degrees=5, translate=(0.5, 0.5)), \\\n",
    "    transforms.ToTensor(), transforms.Normalize(mean=(0.0253), std=(0.1131))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c32687901f65d3de",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:51.782469200Z",
     "start_time": "2023-12-24T12:02:51.697591900Z"
    }
   },
   "outputs": [],
   "source": [
    "class KyrMnistDataset(Dataset):\n",
    "    def __init__(self, features, transform=img_tform_1):\n",
    "        self.features = features.iloc[:, 1:].values.reshape((-1, 50, 50)).astype(np.float32)\n",
    "        self.targets = torch.from_numpy(features.label.values)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.features[idx]), self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "181b9471dc83b1f1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:51.812079700Z",
     "start_time": "2023-12-24T12:02:51.708810100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 3e-4\n",
    "batch_size = 64\n",
    "seed = 42\n",
    "num_epochs = 15\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "990b092bb1be7311",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:51.844720400Z",
     "start_time": "2023-12-24T12:02:51.728532300Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataloaders(seed=seed, validation_size=0.1, df=train_data, batch_size=batch_size):\n",
    "    train_df, val_df = train_test_split(df, test_size=validation_size, random_state=seed, stratify=df['label'])\n",
    "\n",
    "    train_data_1 = KyrMnistDataset(train_df)\n",
    "    train_data_2 = KyrMnistDataset(train_df, img_tform_2)\n",
    "    train_data_3 = KyrMnistDataset(train_df, img_tform_3)\n",
    "    train_data_4 = KyrMnistDataset(train_df, img_tform_4)\n",
    "    train_data_5 = KyrMnistDataset(train_df, img_tform_5)\n",
    "    train_data_6 = KyrMnistDataset(train_df, img_tform_6)\n",
    "    train_final = ConcatDataset([train_data_1, train_data_2, train_data_3,\n",
    "                                 train_data_4, train_data_5, train_data_6])\n",
    "\n",
    "    val_data = KyrMnistDataset(val_df)\n",
    "\n",
    "    train_loader = DataLoader(train_final, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    valid_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25dccc66f9e389e3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:51.869427900Z",
     "start_time": "2023-12-24T12:02:51.744715400Z"
    }
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first.\n",
    "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with\n",
    "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs\n",
    "    with shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format='channels_first'):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        self.normalized_shape = (normalized_shape,)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.data_format == 'channels_last':\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == 'channels_first':\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cba416759288e381",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:51.869427900Z",
     "start_time": "2023-12-24T12:02:51.761803500Z"
    }
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(dim, dim, kernel_size=5, padding=2, groups=dim)\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim)\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.norm = LayerNorm(dim, data_format='channels_last')\n",
    "        self.act = nn.GELU()\n",
    "        self.drop_path = DropPath(0.2)\n",
    "        self.gamma = nn.Parameter(1e-6 * torch.ones((dim)),\n",
    "                                  requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = self.conv1(x)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        x = self.gamma * x\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = res + self.drop_path(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d922880b675c1c38",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:51.874427100Z",
     "start_time": "2023-12-24T12:02:51.776455900Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3),\n",
    "\n",
    "            LayerNorm(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=2, stride=2),\n",
    "\n",
    "            BasicBlock(64),\n",
    "            BasicBlock(64),\n",
    "            BasicBlock(64),\n",
    "\n",
    "            LayerNorm(64),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2),\n",
    "\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "\n",
    "            LayerNorm(128),\n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2),\n",
    "\n",
    "            BasicBlock(256)\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 36)\n",
    "        )\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.trunc_normal_(m.weight, std=2e-2)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Model()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "69e37f188fc95245",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:51.910618300Z",
     "start_time": "2023-12-24T12:02:51.863908900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 48, 48]             640\n",
      "         LayerNorm-2           [-1, 64, 48, 48]             128\n",
      "            Conv2d-3           [-1, 64, 24, 24]          16,448\n",
      "            Conv2d-4           [-1, 64, 24, 24]           1,664\n",
      "         LayerNorm-5           [-1, 24, 24, 64]             128\n",
      "            Linear-6          [-1, 24, 24, 256]          16,640\n",
      "              GELU-7          [-1, 24, 24, 256]               0\n",
      "            Linear-8           [-1, 24, 24, 64]          16,448\n",
      "          DropPath-9           [-1, 64, 24, 24]               0\n",
      "       BasicBlock-10           [-1, 64, 24, 24]               0\n",
      "           Conv2d-11           [-1, 64, 24, 24]           1,664\n",
      "        LayerNorm-12           [-1, 24, 24, 64]             128\n",
      "           Linear-13          [-1, 24, 24, 256]          16,640\n",
      "             GELU-14          [-1, 24, 24, 256]               0\n",
      "           Linear-15           [-1, 24, 24, 64]          16,448\n",
      "         DropPath-16           [-1, 64, 24, 24]               0\n",
      "       BasicBlock-17           [-1, 64, 24, 24]               0\n",
      "           Conv2d-18           [-1, 64, 24, 24]           1,664\n",
      "        LayerNorm-19           [-1, 24, 24, 64]             128\n",
      "           Linear-20          [-1, 24, 24, 256]          16,640\n",
      "             GELU-21          [-1, 24, 24, 256]               0\n",
      "           Linear-22           [-1, 24, 24, 64]          16,448\n",
      "         DropPath-23           [-1, 64, 24, 24]               0\n",
      "       BasicBlock-24           [-1, 64, 24, 24]               0\n",
      "        LayerNorm-25           [-1, 64, 24, 24]             128\n",
      "           Conv2d-26          [-1, 128, 12, 12]          32,896\n",
      "           Conv2d-27          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-28          [-1, 12, 12, 128]             256\n",
      "           Linear-29          [-1, 12, 12, 512]          66,048\n",
      "             GELU-30          [-1, 12, 12, 512]               0\n",
      "           Linear-31          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-32          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-33          [-1, 128, 12, 12]               0\n",
      "           Conv2d-34          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-35          [-1, 12, 12, 128]             256\n",
      "           Linear-36          [-1, 12, 12, 512]          66,048\n",
      "             GELU-37          [-1, 12, 12, 512]               0\n",
      "           Linear-38          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-39          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-40          [-1, 128, 12, 12]               0\n",
      "           Conv2d-41          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-42          [-1, 12, 12, 128]             256\n",
      "           Linear-43          [-1, 12, 12, 512]          66,048\n",
      "             GELU-44          [-1, 12, 12, 512]               0\n",
      "           Linear-45          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-46          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-47          [-1, 128, 12, 12]               0\n",
      "           Conv2d-48          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-49          [-1, 12, 12, 128]             256\n",
      "           Linear-50          [-1, 12, 12, 512]          66,048\n",
      "             GELU-51          [-1, 12, 12, 512]               0\n",
      "           Linear-52          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-53          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-54          [-1, 128, 12, 12]               0\n",
      "           Conv2d-55          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-56          [-1, 12, 12, 128]             256\n",
      "           Linear-57          [-1, 12, 12, 512]          66,048\n",
      "             GELU-58          [-1, 12, 12, 512]               0\n",
      "           Linear-59          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-60          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-61          [-1, 128, 12, 12]               0\n",
      "           Conv2d-62          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-63          [-1, 12, 12, 128]             256\n",
      "           Linear-64          [-1, 12, 12, 512]          66,048\n",
      "             GELU-65          [-1, 12, 12, 512]               0\n",
      "           Linear-66          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-67          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-68          [-1, 128, 12, 12]               0\n",
      "           Conv2d-69          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-70          [-1, 12, 12, 128]             256\n",
      "           Linear-71          [-1, 12, 12, 512]          66,048\n",
      "             GELU-72          [-1, 12, 12, 512]               0\n",
      "           Linear-73          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-74          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-75          [-1, 128, 12, 12]               0\n",
      "           Conv2d-76          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-77          [-1, 12, 12, 128]             256\n",
      "           Linear-78          [-1, 12, 12, 512]          66,048\n",
      "             GELU-79          [-1, 12, 12, 512]               0\n",
      "           Linear-80          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-81          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-82          [-1, 128, 12, 12]               0\n",
      "           Conv2d-83          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-84          [-1, 12, 12, 128]             256\n",
      "           Linear-85          [-1, 12, 12, 512]          66,048\n",
      "             GELU-86          [-1, 12, 12, 512]               0\n",
      "           Linear-87          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-88          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-89          [-1, 128, 12, 12]               0\n",
      "        LayerNorm-90          [-1, 128, 12, 12]             256\n",
      "           Conv2d-91            [-1, 256, 6, 6]         131,328\n",
      "           Conv2d-92            [-1, 256, 6, 6]           6,656\n",
      "        LayerNorm-93            [-1, 6, 6, 256]             512\n",
      "           Linear-94           [-1, 6, 6, 1024]         263,168\n",
      "             GELU-95           [-1, 6, 6, 1024]               0\n",
      "           Linear-96            [-1, 6, 6, 256]         262,400\n",
      "         DropPath-97            [-1, 256, 6, 6]               0\n",
      "       BasicBlock-98            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-99            [-1, 256, 1, 1]               0\n",
      "         Flatten-100                  [-1, 256]               0\n",
      "         Dropout-101                  [-1, 256]               0\n",
      "          Linear-102                   [-1, 36]           9,252\n",
      "================================================================\n",
      "Total params: 2,046,116\n",
      "Trainable params: 2,046,116\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 31.51\n",
      "Params size (MB): 7.81\n",
      "Estimated Total Size (MB): 39.32\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, (1, 50, 50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e6dc767f6cd6a18",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:51.935820400Z",
     "start_time": "2023-12-24T12:02:51.905542500Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    train_acc = 0\n",
    "    total = 0\n",
    "    loop = tqdm(enumerate(dataloader), total=len(dataloader), leave=False, ncols=120)\n",
    "    loop.set_description(f'Epoch: [{epoch + 1}/{num_epochs}]')\n",
    "    for batch_idx, (features, labels) in loop:\n",
    "        inputs, targets = features.to(device, non_blocking=True), labels.to(device, non_blocking=True).long()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total += len(targets)\n",
    "        final_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_acc += ((predicted == targets).sum().item())\n",
    "        if batch_idx % 200 == 0:\n",
    "            loop.update()\n",
    "            loop.set_postfix(loss=f'{final_loss / (batch_idx + 1):.5f}', acc=f'{train_acc / total:.5f}')\n",
    "\n",
    "    final_loss /= len(dataloader)\n",
    "    train_acc = (train_acc / total) * 100\n",
    "\n",
    "    return final_loss, train_acc\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device, epoch, best_result):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    val_acc = 0\n",
    "    total = 0\n",
    "    loop = tqdm(enumerate(dataloader), total=len(dataloader), leave=False)\n",
    "    for batch_idx, (features, labels) in loop:\n",
    "        inputs, targets = features.to(device, non_blocking=True), labels.to(device, non_blocking=True).long()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        total += len(targets)\n",
    "        final_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        val_acc += ((predicted == targets).sum().item())\n",
    "        loop.set_description(f'Epoch: [{epoch + 1}/{num_epochs}]')\n",
    "        loop.set_postfix(loss=final_loss / (batch_idx + 1), acc=val_acc / total)\n",
    "\n",
    "    final_loss /= len(dataloader)\n",
    "    val_acc = (val_acc / total) * 100\n",
    "\n",
    "    if val_acc > best_result:\n",
    "        name = 'best_models/model_v' + str(epoch + 1) + '.pth'\n",
    "        torch.save(model.state_dict(), name)\n",
    "        best_result = val_acc\n",
    "    return final_loss, val_acc, best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "824e6010fdedcd3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:52.770474100Z",
     "start_time": "2023-12-24T12:02:51.925711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.1653, 1.1611, 1.1685, 1.1658, 1.1637, 1.1564, 1.1798, 1.1798, 1.1538,\n        1.1616, 1.1334, 1.1648, 1.1137, 1.1611, 1.1590, 1.0051, 1.1669, 1.0000,\n        1.1749, 1.1680, 1.1722, 1.1658, 1.3991, 1.0020, 1.1658, 1.1669, 1.1765,\n        1.1225, 1.1685, 1.1674, 1.1653, 1.1658, 1.1653, 1.1658, 1.1690, 1.1374],\n       device='cuda:0')"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = train_data.copy()\n",
    "weights['count_of_targets'] = weights['label'].map(weights['label'].value_counts())\n",
    "weights.sort_values('label', inplace=True)\n",
    "weights.drop_duplicates('label', inplace=True)\n",
    "n_samples = list(weights['count_of_targets'])\n",
    "weights = [(max(n_samples) / n) for n in n_samples]\n",
    "loss_weights = torch.FloatTensor(weights).to(device)\n",
    "loss_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4fde1d8fb4c3081e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:52.810630300Z",
     "start_time": "2023-12-24T12:02:52.772473700Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_training(seed, train_acc_lst, train_loss_lst, val_acc_lst, val_loss_lst):\n",
    "    train_loader, valid_loader = create_dataloaders(seed=seed)\n",
    "    best_result = 0\n",
    "\n",
    "    optimizer = Lion(model.parameters(), lr=learning_rate, weight_decay=3e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=num_epochs, eta_min=3e-4)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=loss_weights)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      \n",
    "        train_loss, train_acc = train_fn(model, optimizer, scheduler, loss_fn, train_loader, device, epoch)\n",
    "     \n",
    "        train_acc_lst.append(train_acc)\n",
    "      \n",
    "        train_loss_lst.append(train_loss)\n",
    "     \n",
    "        val_loss, val_acc, best_result = valid_fn(model, loss_fn, valid_loader, device, epoch, best_result)\n",
    "\n",
    "        val_acc_lst.append(val_acc)\n",
    "      \n",
    "        val_loss_lst.append(val_loss)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66062ec40b4d985e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:52.823039200Z",
     "start_time": "2023-12-24T12:02:52.785809300Z"
    }
   },
   "outputs": [],
   "source": [
    "train_acc_lst = []\n",
    "train_loss_lst = []\n",
    "val_acc_lst = []\n",
    "val_loss_lst = []\n",
    "# run_training(seed, train_acc_lst, train_loss_lst, val_acc_lst, val_loss_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "Model(\n  (feature_extractor): Sequential(\n    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n    (1): LayerNorm()\n    (2): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n    (3): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n      (pwconv1): Linear(in_features=64, out_features=256, bias=True)\n      (pwconv2): Linear(in_features=256, out_features=64, bias=True)\n      (norm): LayerNorm()\n      (act): GELU(approximate='none')\n      (drop_path): DropPath(drop_prob=0.200)\n    )\n    (4): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n      (pwconv1): Linear(in_features=64, out_features=256, bias=True)\n      (pwconv2): Linear(in_features=256, out_features=64, bias=True)\n      (norm): LayerNorm()\n      (act): GELU(approximate='none')\n      (drop_path): DropPath(drop_prob=0.200)\n    )\n    (5): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n      (pwconv1): Linear(in_features=64, out_features=256, bias=True)\n      (pwconv2): Linear(in_features=256, out_features=64, bias=True)\n      (norm): LayerNorm()\n      (act): GELU(approximate='none')\n      (drop_path): DropPath(drop_prob=0.200)\n    )\n    (6): LayerNorm()\n    (7): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n    (8): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\n      (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n      (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n      (norm): LayerNorm()\n      (act): GELU(approximate='none')\n      (drop_path): DropPath(drop_prob=0.200)\n    )\n    (9): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\n      (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n      (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n      (norm): LayerNorm()\n      (act): GELU(approximate='none')\n      (drop_path): DropPath(drop_prob=0.200)\n    )\n    (10): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\n      (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n      (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n      (norm): LayerNorm()\n      (act): GELU(approximate='none')\n      (drop_path): DropPath(drop_prob=0.200)\n    )\n    (11): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\n      (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n      (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n      (norm): LayerNorm()\n      (act): GELU(approximate='none')\n      (drop_path): DropPath(drop_prob=0.200)\n    )\n    (12): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\n      (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n      (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n      (norm): LayerNorm()\n      (act): GELU(approximate='none')\n      (drop_path): DropPath(drop_prob=0.200)\n    )\n    (13): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\n      (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n      (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n      (norm): LayerNorm()\n      (act): GELU(approximate='none')\n      (drop_path): DropPath(drop_prob=0.200)\n    )\n    (14): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\n      (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n      (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n      (norm): LayerNorm()\n      (act): GELU(approximate='none')\n      (drop_path): DropPath(drop_prob=0.200)\n    )\n    (15): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\n      (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n      (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n      (norm): LayerNorm()\n      (act): GELU(approximate='none')\n      (drop_path): DropPath(drop_prob=0.200)\n    )\n    (16): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\n      (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n      (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n      (norm): LayerNorm()\n      (act): GELU(approximate='none')\n      (drop_path): DropPath(drop_prob=0.200)\n    )\n    (17): LayerNorm()\n    (18): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n    (19): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)\n      (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n      (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n      (norm): LayerNorm()\n      (act): GELU(approximate='none')\n      (drop_path): DropPath(drop_prob=0.200)\n    )\n  )\n  (avgpool): Sequential(\n    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n  )\n  (classifier): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Dropout(p=0.2, inplace=False)\n    (2): Linear(in_features=256, out_features=36, bias=True)\n  )\n)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model.load_state_dict(torch.load('model_v11.pth'))\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:52.946135800Z",
     "start_time": "2023-12-24T12:02:52.799540300Z"
    }
   },
   "id": "d60f1f448f215d28"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "first_column = df.iloc[:, 1:2502]\n",
    "\n",
    "image_data = first_column.values.reshape((len(df), 50, 50))\n",
    "tensor_data = torch.tensor(image_data[6788], dtype=torch.float32)\n",
    "normalize = transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "tensor_data = tensor_data.view(1, 1, 50, 50)\n",
    "tensor_data = normalize(tensor_data)\n",
    "ans = model(tensor_data)\n",
    "print(torch.argmax(ans))\n",
    "\n",
    "first_column = df.iloc[:, 1:2502]\n",
    "\n",
    "image_data = first_column.values.reshape((len(df), 50, 50))\n",
    "plt.imshow(image_data[6788], cmap='gray') \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T12:02:55.554408200Z",
     "start_time": "2023-12-24T12:02:52.944618600Z"
    }
   },
   "id": "89aaf264ffc305fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
